# ACE-ProtoNet

**Adaptive Covariance Eigen-Gate and Uncertainty-Aware Prototype Learning for Coronary Artery Segmentation**

This repository contains the **official PyTorch implementation** of our paper:

> **ACE-ProtoNet: Adaptive Covariance Eigen-Gate and Uncertainty-Aware Prototype Learning for Coronary Artery Segmentation**

---


## âœ¨ Key Features

* End-to-end 3D segmentation framework
* Covariance-driven structural gating mechanism
* Uncertainty-aware prototype learning
* Fully reproducible training and evaluation pipeline

---

## ğŸ› ï¸ Requirements

The codebase is implemented in **Python (â‰¥3.8)** using **PyTorch**.

We strongly recommend creating a virtual environment.

### Install Dependencies

```bash
# Install PyTorch (adjust CUDA version if necessary)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install additional dependencies
pip install numpy SimpleITK tqdm scikit-learn
```

---

## ğŸ“‚ Data Preparation

As used in `train.py` and `test.py`, the preprocessed CCTA data should be organized in the following structure.

All volumes are expected in **NumPy (`.npy`) format**.

```
Data/
â””â”€â”€ npy/
    â”œâ”€â”€ img/
    â”‚   â”œâ”€â”€ 1.npy
    â”‚   â”œâ”€â”€ 2.npy
    â”‚   â””â”€â”€ ...
    â””â”€â”€ mask/
        â”œâ”€â”€ 1.npy
        â”œâ”€â”€ 2.npy
        â””â”€â”€ ...
```

### Directory Description

* `img/` â€” Preprocessed CCTA volumes
* `mask/` â€” Corresponding ground-truth coronary artery masks

âš ï¸ **Important:**
Each imageâ€“mask pair **must share the same filename**.
For example:

```
img/1.npy  â†”  mask/1.npy
```

---

### ğŸ”€ Dataset Splitting

A dataset splitting utility is provided:

```
datasets/create_folder.py
```

This script:

* Automatically generates the required folder structure
* Splits the dataset into training / validation / testing subsets
* Ensures reproducibility of experimental results

---

## ğŸš€ Usage

### 1ï¸âƒ£ Training

To train ACE-ProtoNet on your prepared dataset:

```bash
python train.py
```

---

### 2ï¸âƒ£ Evaluation / Testing

To evaluate a trained model on the test set:

```bash
python test.py
```

---
## ğŸ” Post-processing

To further improve segmentation quality and suppress small false-positive regions, we provide simple yet effective post-processing utilities in:

```
postprocess/
â”œâ”€â”€ get_patch.py
â””â”€â”€ keep_the_largest_area.py
```

### 1ï¸âƒ£ `keep_the_largest_area.py`

Removes small disconnected components from the predicted segmentation and retains only the largest connected region.

This is particularly useful for coronary artery segmentation, where small isolated predictions may appear due to noise or uncertainty in low-contrast regions.

**Purpose:**

* Eliminate false-positive fragments
* Improve structural consistency
* Enhance quantitative evaluation stability

---

### 2ï¸âƒ£ `get_patch.py`

Extracts local patches from volumetric predictions for further refinement or analysis.

---

## ğŸ“¦ Pre-trained Weights

Due to GitHub file size limitations, pretrained checkpoints are hosted externally.

| Dataset   | Checkpoint             | Download                                                                                              |
| --------- | ---------------------- | ----------------------------------------------------------------------------------------------------- |
| **ASOCA** | `model_best_model.ptk` | [ğŸ”— Google Drive](https://drive.google.com/file/d/1unZwue8W2pGoleUawu-85CrCMlljtw7T/view?usp=sharing) |

### Usage Instructions

1. Download the checkpoint file
2. Place it in:

```
./checkpoints/
```

3. Run `test.py` for evaluation

---

## ğŸ“Š Reproducibility

To ensure reproducibility:

* Use identical data preprocessing
* Maintain consistent file naming conventions
* Verify CUDA / PyTorch compatibility

For exact experimental settings, please refer to the paper.


---

## ğŸ“§ Contact

If you encounter any issues or have questions:

* Please open an issue in this repository
* Or contact the authors via  caixia_dong@xjtu.edu.cn

We sincerely appreciate your interest in our work.
If this repository is helpful, a â­ star would be greatly appreciated!
